{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b501a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 사용에 필요한 라이브러리 불러오기\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d60cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing Arguments\n",
    "# python DCGAN practice.py \n",
    "# python DCGAN practice.py -h  : help \n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # 11개의 parser\n",
    "    parser.add_argument(\"--n_epochs\", type=int, default=500, help=\"number of epochs for training\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-4, help=\"adam: learning rate\")\n",
    "    parser.add_argument(\"--b1\", type=float, default=0.5, help=\"decay of first order momentum of gradient\")\n",
    "    parser.add_argument(\"--b2\", type=float, default=0.999, help=\"decay of first order momentum of gradient\")\n",
    "    # 잠재 공간\n",
    "    parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "    parser.add_argument(\"--img_size\", type=int, default=48, help=\"size of each image dimension\")\n",
    "    parser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\n",
    "    parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image samples\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=777, help=\"seed number\")\n",
    "    parser.add_argument(\"--object\", type=str, default='data', help=\"which object to generate\")\n",
    "    \n",
    "    args.parser.parse_args()\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0b8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "def set_dataloader(args):\n",
    "    \n",
    "    # args.object = \"--object\"\n",
    "    dataset = datasets.ImageFolder(root='.data/{}'.format(args.object),\n",
    "                                   transforms=transforms.Compose([\n",
    "                                       transforms.Resize((args.img_size, args.img_size)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5], [0.5])\n",
    "                                   ]))\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a00b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, image_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim \n",
    "        self.image_shape = image_shape\n",
    "        \n",
    "        def block(input_fea, output_fea, normalize=True): # 함수내에 함수 선언 형태\n",
    "            layers = [nn.Linear(input_fea, output_fea)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(output_fea, 0.5))\n",
    "\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "            return layers\n",
    "        \n",
    "        # 인자길이를 모를 떄 길이를 가변 가능하도록 * 붙임\n",
    "        # * args : 하나의 argument\n",
    "        # ** ketargs : keyword argument(딕셔너리 형태의 인자들)\n",
    "        self.model = nn.Sequential(\n",
    "        *block(latent_dim, 128, normalize=False),\n",
    "        *block(128, 256),\n",
    "        *block(512, 1024),\n",
    "        nn.Linear(1024, int(np.prod(image_shape))),\n",
    "        nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        image = self.model(z)\n",
    "        image = image.view(image.size(0), *self.image_shape)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b920fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # CNN 구조\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Linear(int(np.prod(image_shape)), 512), \n",
    "                 nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "                 nn.Linear(512, 256),\n",
    "                 nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "                 nn.Linear(256, 1),\n",
    "                 nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        image_flat = image.view(image.size(0), -1)\n",
    "        validity = self.model(image_flat)\n",
    "        \n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4282c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정과 하이퍼 파라미터 선언\n",
    "import random\n",
    "def set_seed(args): # 값이 변화하는 것을 막아주기\n",
    "    random.seed(args.seed) # paser의 args에 접근\n",
    "    np.randomseed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    \n",
    "def main(): # main을 통해 args를 접근\n",
    "    # seed setting\n",
    "    set_seed(args)\n",
    "    dataloader = set_dataloader(args)\n",
    "    \n",
    "    image_shape = (args.channels, arg.img_size, args.img_size) # rgb(3), 48 * 48\n",
    "    \n",
    "    # 한줄로도 표현 가능한 코드\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda : 0\")\n",
    "        Tensor = torch.cuda.FloatTensor\n",
    "        \n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        Tensor = torch.FloatTensor\n",
    "    \n",
    "    print(\"Current Device : {} \\t Base Tensor : {}\".format(device, Tensor))\n",
    "    \n",
    "    criterion = torch.nn.BCELoss().to(device)\n",
    "    generator = Generator(args.latent_dim, image_shape).to(device)\n",
    "    discriminator = Discriminator(image_shape).to(device)\n",
    "    \n",
    "    # betas : Adam에서 사용하는 momentum의 개수\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=args.lr, betas=(args.b1, args.b2))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=args.lr, betas=(args.b1, args.b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b148af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def train(args, device, dataloader, criterion, generator, discriminator, optimizer_G, optimizer_D, Tensor):\n",
    "    experiment_time = datetime.today().strftime(\"%Y%m%d_%H_%M\") # 얼마나 시간이 걸렸는지\n",
    "    result_dir = 'images/{}'.format(experiment_time) # str 형식으로 폴더에 저장\n",
    "    model_dir = 'trained_model/{}'.format(experiment_time)\n",
    "    \n",
    "    os.makedirs(result_dir, exist_ok=False) # 기존에 있는 폴더를 사용한다\n",
    "    os.makedirs(model_dir, exist_ok=False)\n",
    "    \n",
    "    for epoch in range(args.n_epochs):\n",
    "        for idx, data in enumerate(dataloader): # index\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # 실제 이미지(Ground Truth)\n",
    "            valid = Variable(Tensor(images.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "            fake = Variable(Tensor(images.size(0), 1).fill(0.0), requires_grad=False)\n",
    "            \n",
    "            real_images = Variable(image.type(Tensor))\n",
    "            \n",
    "            ## generator training\n",
    "            optimizer_G.zero_grad()\n",
    "            # optimizer.G.zero_grad()\n",
    "            \n",
    "            # generator sample noise input\n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (images.size(0), args.latent_dim))))\n",
    "            \n",
    "            # generator가 만들어낸 가짜 이미지\n",
    "            gen_images = generator(z)\n",
    "            \n",
    "            loss_G = criterion(discriminator(gen_images), valid)\n",
    "            \n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            ## discriminator training\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            loss_real = criterion(discriminator(real_images), valid)\n",
    "            loss_fake = criterion(discriminator(gen_images.detach()), fake)\n",
    "            loss_D = (loss_real + loss_fake) / 2\n",
    "            \n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # training ...\n",
    "            if idx % 20 == 0:\n",
    "                print(\"[Epoch: {:d}/{:d}] \\t [Batch {:d}/{:d}] \\t [Loss_G {:.4f}] \\t [Loss_D {:.4f}]\"\n",
    "                     .format(epoch, args.n_epochs, idx, len(dataloader), loss_G.item(), loss_D.item()))\n",
    "            \n",
    "            batches_done = epoch * len(dataloader) + idx\n",
    "            \n",
    "            if batches_done % args.sample_interval == 0:\n",
    "                print('Save sample image')\n",
    "                # batch가 끝났을 때 이미지 저장\n",
    "                save_image(gen_images.data[:25],'{}/{:d}.png'\n",
    "                           .format(result_dir, batches_done), nrow=5, normalize=True)\n",
    "                \n",
    "        print('Everything Done... Saving Model')\n",
    "        \n",
    "        # save model\n",
    "        PATH_G = model_dir + '/generator.pth'\n",
    "        PATH_D = model_dir + '/discriminator.pth'\n",
    "        \n",
    "        # save\n",
    "        torch.save(generator.state_dict(), PATH_G)\n",
    "        torch.save(discriminator.state_dict(), PATH_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20eb1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
